+++
title = "Http2简介"
date = 2020-12-16

[taxonomies]
categories = ["Tech"]
tags = ["http"]
+++

在谈HTTP/2的之前，需要先谈一谈SPDY，因为HTTP/2从一开始就是基于SPDY起草的。而且，后续SPDY已经成为了HTTP/2新特性的一种校验和测试。

# SPDY

SPDY是Google开发的一个实验性协议，发布于2009年年中，主要解决HTTP/1.1中一些性能限制，用来减少网页的加载延迟。SPDY一开始设定的目标如下：

- 页面加载时间 (PLT) 减少 50%。
- 无需网站作者修改任何内容。
- 将部署复杂性降至最低，无需变更网络基础设施。
- 与开源社区合作开发此新协议。
- 收集真实性能数据，验证实验性协议是否有效。

> 注：为了达到减少 50% 页面加载时间的目标，SPDY 引入一个新的二进制分帧层，以实现请求和响应复用、优先级和标头压缩，目的是更有效地利用底层 TCP 连接；请参阅延迟是性能瓶颈。

首发后不久，Google的两位软件工程师 Mike Belshe 和 Roberto Peon 在实验室环境，通过模拟的家庭网络连接，下载了 25 个最流行的网站，发现性能的提升特别明显：页面加载速度最高加快了55%。

2012年，SPDY得到 Chrome、Firefox 和 Opera 的支持，而且越来越多的大型网站（如 Google、Twitter、Facebook）和小型网站开始在其基础设施内部署SPDY。在被行业越来越多的采用之后，它已经具备了成为一个标准的条件。

# HTTP/2

HTTP2的第一个草案在2012年11月确定的，最重要的是：它是基于SPDY的。之后的几年中，SPDY 和 HTTP/2 共同演变和发展，但 SPDY 是作为实验性分支，用于为 HTTP/2 标准测试新功能和建议。它提供一个测试和评估路线，对要纳入 HTTP/2 标准中的每条建议进行测试和评估。 最终，这个过程持续了三年，期间产生了十余个中间草案。具体时间点为：

- 2012 年 3 月：征集 HTTP/2 建议
- 2012 年 11 月：第一个 HTTP/2 草案（基于 SPDY）
- 2014 年 8 月：HTTP/2 草案 17 和 HPACK 草案 12 发布
- 2014 年 8 月：工作组最后一次征集 HTTP/2 建议
- 2015 年 2 月：IESG 批准 HTTP/2 和 HPACK 草案
- 2015 年 5 月：RFC 7540 (HTTP/2) 和 RFC 7541 (HPACK) 发布

2015 年初，IESG 审阅了新的 HTTP/2 标准并批准发布。 之后不久，Google Chrome 团队公布了他们为 TLS 弃用 SPDY 和 NPN 扩展的时间表。

## 为什么是HTTP/2

为什么叫HTTP/2，而不是HTTP/1.2呢？原因如下：

HTTP/2 的主要变化是为了实现 HTTP 工作组设定的性能目标。与 HTTP/1.1 相比，HTTP/2 引入了一个新的二进制分帧层，该层无法与之前的 HTTP/1.x 服务器和客户端向后兼容，因此协议的主版本提升到 HTTP/2。

但需要注意的是，HTTP/2 仍是对 HTTP 标准的扩展，而非替代。所以，对于 HTTP 的应用语义不变，提供的功能不变，HTTP 方法、状态代码、URI 和标头字段等这些核心概念也不发生变化。

# 二进制分帧层

虽然 对 HTTP 的高级 API 保持不变，但我们仍然有必要去了解一些低级的变更，去了解这些变更是如何解决了之前协议的性能限制。 我们来简单了解一下二进制分帧层及其功能：

HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。

![二进制分帧层](/static/media/binary_framing_layer_01.jpg)

这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用`二进制格式`对它们编码。

这样一来，客户端和服务器为了相互理解，都必须使用新的二进制编码机制。所以，HTTP/1.x 客户端无法理解只支持 HTTP/2 的服务器，反之亦然。 不过不要紧，现有的应用不必担心这些变化，因为客户端和服务器会替我们完成必要的分帧工作。

# 数据流、消息 和 帧

新的二进制分帧机制改变了客户端与服务器之间交换数据的方式。 对此，我们需要了解 HTTP/2 的三个概念：

### 数据流
已建立的连接内的双向字节流，可以承载一条或多条消息。

### 消息
与逻辑请求或响应消息对应的完整的一系列帧。

### 帧
HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。

它们的关系如下：

- 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。
- 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。
- 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。
- 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。

![Connection的组成](/static/media/connection.jpg)

简单说来，HTTP/2 将 HTTP 协议通信分解为二进制编码帧（如上图）的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 这是 HTTP/2 协议所有其他功能和性能优化的基础。

# 请求与响应复用

在 HTTP/1.x 中，一个连接一个时刻只能进行一次HTTP数据交互。如果客户端要想发起多个并行请求，则必须使用多次 TCP 连接。这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。

而 HTTP/2 中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。

![HTTP2的请求和响应复用](/static/media/connection2.jpg)

上图中，同一个连接内并行了3个数据流：

- 客户端正在向服务器传输一个 DATA 帧（数据流 5）
- 与此同时，服务器正向客户端交错发送数据流 1 和数据流 3 的一系列帧

将 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装是 HTTP 2 最重要的一项增强。这个机制会在整个网络技术栈中引发一系列连锁反应，从而带来巨大的性能提升，使我们可以：

- 并行交错地发送多个请求，请求之间互不影响。
- 并行交错地发送多个响应，响应之间互不干扰。
- 使用一个连接并行发送多个请求和响应。
- 不必再为绕过 HTTP/1.x 限制而做很多工作（主要对 HTTP/1.x 进行优化，例如级联文件、image sprites 和域名分片。）
- 消除不必要的延迟和提高现有网络容量的利用率，从而减少页面加载时间。
- 等等…

HTTP/2 中的新二进制分帧层解决了 HTTP/1.x 中存在的队列阻塞问题，也消除了并行处理和发送请求和响应时对多个连接的依赖。 所以，应用的速度更快、开发更简单、部署成本更低。

# 数据流优先级

将 HTTP 消息分解为很多独立的帧之后，我们就可以复用多个数据流中的帧，客户端和服务器交错发送和传输这些帧的顺序就成为关键的性能决定因素。 为了做到这一点，HTTP/2 标准允许每个数据流都有一个关联的权重和依赖关系：

- 可以向每个数据流分配一个介于 1 至 256 之间的整数。
- 每个数据流与其他数据流之间可以存在显式依赖关系。

数据流依赖关系和权重的组合让客户端可以构建和传递“优先级树”，表明它倾向于如何接收响应。 反过来，服务器可以使用此信息通过控制 CPU、内存和其他资源的分配设定数据流处理的优先级，在资源数据可用之后，带宽分配可以确保将高优先级响应以最优方式传输至客户端。

![优先级树](/static/media/stream_tree.jpg)

上面是一个“优先级树”的示意图。

HTTP/2 内的数据流依赖关系通过将另一个数据流的唯一标识符作为父项引用进行声明。如果忽略标识符，相应数据流将依赖于“根数据流”。 通过声明数据流依赖关系，会尽可能先向父数据流分配资源，然后再向其依赖项分配资源。 换句话说，上图中，会先处理和传输响应 D，然后再处理和传输响应 C。因为D是C的父项引用。

共享相同父项的数据流（即：同级数据流）应按其权重比例分配资源。上图中，数据流 A 的权重为 12，数据流 B 的权重为 4，如何确定A和B的资源比例呢？

1. 将所有权重求和：4 + 12 = 16
2. 将每个数据流权重除以总权重：A = 12/16 = 3/4 , B = 4/16 = 1/4

所以，数据流 A 获得3/4的可用资源，数据流 B 应获得1/4的可用资源。

我们再来看一下上图中的完整操作示例。 从左到右依次为：

1. 数据流 A 和数据流 B 都没有指定父依赖项，依赖于隐式“根数据流”；A 的权重为 12，B 的权重为 4。因此，根据比例权重：数据流 B 获得的资源是 A 所获资源的1/3。
2. 数据流 D 依赖于根数据流，C 依赖于 D。 因此，D 应先于 C 获得完整资源分配。 在这里，权重不重要，因为 C 的依赖关系拥有更高的优先级。
3. 数据流 D 应先于 C 获得完整资源分配，C 应先于 A 和 B 获得完整资源分配，数据流 B 获得的资源是 A 所获资源的1/3。
4. 数据流 D 应先于 E 和 C 获得完整资源分配，E 和 C 应先于 A 和 B 获得相同的资源分配，A 和 B 应基于其权重获得比例分配。

通过上面的示例，我们了解到：数据流通过『依赖关系』和『权重』的组合，明确表达了资源优先级，而这正是一种用于提升浏览性能的关键功能。网络中拥有多种资源类型，它们的依赖关系和权重各不相同。 不仅如此，HTTP/2 协议还允许客户端随时更新这些优先级，进一步优化了浏览器性能。 换句话说，我们可以根据用户互动和其他信号更改依赖关系和重新分配权重。

> 注：数据流通过依赖关系和权重表示传输优先级，但它不是绝对的。因此不能保证特定的处理或传输顺序。 即，客户端无法强制服务器通过数据流优先级以特定顺序处理数据流。 尽管这看起来违反了HTTP/2的理论准则，但却是一种必要行为。因为我们不希望服务器在处理优先级较高的资源受到阻止时，不能处理优先级较低的资源。

# 每个来源仅需一个连接

有了新的分帧机制后，HTTP/2 不再依赖多个 TCP 连接去并行复用数据流。每个数据流都拆分成很多帧，而这些帧可以交错，还可以分别设定优先级。 所以， HTTP/2 的连接都是长连接的，而且每个来源仅需要一个连接，这样就能带来诸多性能优势。

> HTTP/2 的杀手级功能是，能够在一个拥塞受到良好控制的通道上任意进行复用。 

通过重用相同的连接，HTTP/2 可以更有效地利用每个 TCP 连接，也可以显著降低整体协议开销。 不仅如此，使用更少的连接还可以减少占用的内存和处理空间，也可以缩短完整连接路径（即，客户端、可信中介和源服务器之间的路径）。这降低了整体运行成本，并提高了网络利用率和容量。 因此，迁移到 HTTP/2 不仅可以减少网络延迟，还有助于提高通量和降低运行成本。

> 注：连接数量减少对提升 HTTPS 部署的性能来说是一项特别重要的功能：可以减少开销较大的 TLS 连接数、提升会话重用率，以及从整体上减少所需的客户端和服务器资源。

# 流控制

流控制是一种阻止`发送方`向`接收方`发送大量数据的机制，以免超出后者的需求或处理能力：发送方可能非常繁忙、处于较高的负载之下，也可能仅仅希望为特定数据流分配固定量的资源。 下面是两个例子：
1. 客户端可能请求了一个具有较高优先级的大型视频流，但是用户已经暂停视频，客户端现在希望暂停或限制从服务器的传输，以免提取和缓冲不必要的数据。 
2. 一个代理服务器可能具有较快的下游连接和较慢的上游连接，并且也希望调节下游连接传输数据的速度以匹配上游连接的速度来控制其资源利用率

诸如此类的场景还有很多。在这些场景中，你一定会想到用TCP来进行流控制。但是在HTTP/2中，由于TCP是复用的，所以，通过TCP来进行流控制并不精确，也就无法提供必要的应用级 API 来调节各个数据流的传输。 为了解决这一问题，HTTP/2 提供了一组简单的构建块，这些构建块允许客户端和服务器实现其自己的数据流和连接级流控制：

- 流控制具有方向性。 每个接收方都可以根据自身需要选择为每个数据流和整个连接设置任意的窗口大小。
- 流控制基于信用。 每个接收方都可以公布其初始连接和数据流流控制窗口（以字节为单位），每当发送方发出 DATA 帧时都会减小，在接收方发出 WINDOW_UPDATE 帧时增大。
- 流控制无法停用。 建立 HTTP/2 连接后，客户端将与服务器交换 SETTINGS 帧，这会在两个方向上设置流控制窗口。 流控制窗口的默认值设为 65,535 字节，但是接收方可以设置一个较大的最大窗口大小（2^31-1 字节），并在接收到任意数据时通过发送 WINDOW_UPDATE 帧来维持这一大小。
- 流控制为逐跃点控制，而非端到端控制。 即，可信中介可以使用它来控制资源使用，以及基于自身条件和启发式算法实现资源分配机制。

HTTP/2 未指定任何特定算法来实现流控制。但它提供了简单的构建块，让客户端和服务器可以实现自定义策略来调节资源使用和分配，以及实现新传输能力，同时提升网页应用的实际性能和感知性能。例如：

- 应用层流控制允许浏览器仅提取一部分特定资源，通过将数据流流控制窗口减小为零来暂停提取，稍后再行恢复。 换句话说，它允许浏览器提取图像预览或首次扫描结果，进行显示并允许其他高优先级提取继续，然后在更关键的资源完成加载后恢复提取。

# 服务器推送

HTTP/2 新增的另一个强大的新功能是，服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源，而无需客户端明确地请求。

![服务器推送](/static/media/server-push.jpg)

> 注意：HTTP/2 打破了严格的请求-响应语义，支持一对多和服务器发起的推送工作流，在浏览器内外开启了全新的互动可能性。 这是一项使能功能，对我们思考协议、协议用途和使用方式具有重要的长期影响。

为什么在浏览器中需要一种此类机制呢？一个典型的网络应用包含多种资源，客户端需要检查服务器提供的文档才能逐个找到它们。为什么不让服务器提前推送这些资源，从而减少额外的延迟时间呢？当服务器已经知道客户端下一步要请求什么资源，这时候服务器推送就可以派上用场。

在HTTP/2中，如果网页中内联过 CSS、JS、IMAGE 或 通过 URI 内联的其他资源，那么实际上是服务器将资源推送给客户端，而不是等待客户端的请求。服务器推送资源可以进行以下处理，从而获得其他性能优势：

- 由客户端缓存
- 在不同页面之间重用
- 与其他资源一起复用
- 由服务器设定优先级
- 被客户端拒绝

## PUSH_PROMISE 101

所有服务器推送数据流都由 PUSH_PROMISE 帧发起，表明了服务器向客户端推送所述资源的意图，并且需要先于请求推送资源的响应数据传输。这种传输顺序非常重要：客户端需要了解服务器打算推送哪些资源，以免为这些资源创建重复请求。满足此要求的最简单策略是先于父响应（即，DATA 帧）发送所有 PUSH_PROMISE 帧，其中包含所承诺资源的 HTTP 标头。

在客户端接收到 PUSH_PROMISE 帧后，它可以根据自身情况选择拒绝数据流（通过 RST_STREAM 帧）。例如：资源已经在缓存中。 

使用 HTTP/2，客户端完全掌控服务器推送的使用方式。它可以限制并行推送的数据流数量，可以调整初始的流控制窗口以控制在数据流首次打开时推送的数据量，也可以完全停用服务器推送。 这些优先级在 HTTP/2 连接开始时通过 SETTINGS 帧传输，可随时更新。

推送的每个资源都是一个数据流，客户端可以对推送的资源逐一复用、设定优先级和处理。 浏览器强制执行的唯一安全限制是：推送的资源必须符合原点相同（可以简单理解为：相同host）这一政策。

# 标头压缩

每个 HTTP 传输都承载一组标头，这些标头说明了传输的资源及其属性。 在 HTTP/1.x 中，此数据为纯文本形式，通常会给每个传输增加 500–800 字节的开销。如果使用 HTTP Cookie，增加的开销有时会达到上千字节。为了减少开销和提升性能，HTTP/2 使用 HPACK 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术：

1. 这种格式支持通过`静态霍夫曼`编码对传输的标头字段进行编码，从而减小了各个传输的大小。
2. 这种格式要求客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表（换句话说，它可以建立一个共享的压缩上下文），此列表随后会作为参考，用在对之前传输的值进行有效编码。

利用霍夫曼编码，可以在传输时对各个值进行压缩。而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可用于有效查询和重构完整的标头键值对。

![表头压缩](/static/media/compress.jpg)

作为一种进一步优化方式，HPACK 压缩上下文包含一个静态表和一个动态表：

- 静态表在规范中定义，并提供了一个包含所有连接都可能使用的常用 HTTP 标头字段的列表。例如：有效标头名称 等
- 动态表最初为空，将根据在特定连接内交换的值进行更新。 因此，对之前未见过的值采用`静态霍夫曼` 编码，并替换静态表或动态表中已存在值的索引，可以减小每个请求的大小。

> 注：在 HTTP/2 中，请求和响应标头字段的定义保持不变，仅有一些微小的差异：所有标头字段名称均为小写，请求行现在拆分成各个 :method、:scheme、:authority 和 :path 伪标头字段

## HPACK 的安全性和性能

早期版本的 HTTP/2 和 SPDY 使用 zlib（带有一个自定义字典）压缩所有 HTTP 标头。 这种方式可以将所传输标头数据的大小减小 85% - 88%，显著减少了页面加载时间延迟。

在2012 年夏，出现了针对 TLS 和 SPDY 压缩算法的“犯罪”安全攻击，此攻击会导致会话被劫持。 因此，zlib 被 HPACK 压缩算法替代。后者经过专门设计，在保证对HTTP表头元数据进行良好压缩的同时，还可以解决发现的安全问题，而且实现起来也更高效和简单。
